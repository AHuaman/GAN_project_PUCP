{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsLlD0-9JiTr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "xPgWSsjr9rbc",
    "outputId": "cfbed504-bf6e-424c-cb08-24c8650fe3b6"
   },
   "outputs": [],
   "source": [
    "# !pip install -U PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4SwC9ea9uI5"
   },
   "outputs": [],
   "source": [
    "#Import authentication libraries\n",
    "\n",
    "# from google.colab import auth\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN5MzVEF9y7E"
   },
   "outputs": [],
   "source": [
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wln-wC4aHWHy"
   },
   "outputs": [],
   "source": [
    "# folder_id='1uXkcRXuQ5fFG0S8mLW67ewj_jsqAb_Ff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Nl-diLK0-9UL",
    "outputId": "a0e473b1-a532-4629-adb4-0e7c3dffe717"
   },
   "outputs": [],
   "source": [
    "# # Auto-iterate through all files in the midi folder.\n",
    "# file_list = drive.ListFile({'q': \"'{0}' in parents and trashed=false\".format(folder_id)}).GetList()\n",
    "# for file1 in file_list:\n",
    "#   print('title: {0}, id: {1}'.format(file1['title'], file1['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8hWXhkOECVP"
   },
   "outputs": [],
   "source": [
    "# # Download all midi files\n",
    "# for file1 in file_list:\n",
    "#   file_id=file1['id']\n",
    "#   file_title = file1['title']\n",
    "#   drive.CreateFile({'id': file_id}).GetContentFile(file_title)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_HCdPhRQbNz"
   },
   "outputs": [],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSvst7nFQhQb"
   },
   "outputs": [],
   "source": [
    "# echo %cd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder ='C:/Users/Gustavo/Documents/GitHub/MidiNet_test/cond2d'\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svj4H-45V72z"
   },
   "outputs": [],
   "source": [
    "# songs=[f for f in listdir(folder)]\n",
    "# print(songs)\n",
    "# songs=songs[-10:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCMRauAuK8y3"
   },
   "outputs": [],
   "source": [
    "# data_songs=np.empty((0,16,128), int)\n",
    "# for song in songs:\n",
    "#   song_opened = open(song,\"rb\")\n",
    "#   song_loaded= pickle.load(song_opened)\n",
    "#   #for track 1\n",
    "#   for i in range(len(song_loaded[0])):\n",
    "#     bar=np.empty((0,128), int)[None]\n",
    "#     for j in song_loaded[0][i]:\n",
    "#       note=np.zeros(128)[None][None]\n",
    "#       if type(j) == type(1.5):\n",
    "#         note[0,0,int(j)] = 1\n",
    "#       bar=np.append(bar,note,axis=1)\n",
    "#     data_songs =np.append(data_songs,bar, axis=0)\n",
    "#   print(np.array(data_songs).shape)\n",
    "# data_songs_prev =np.roll(data_songs,1,axis=0)\n",
    "# data_songs=data_songs[None]\n",
    "# data_songs_prev=data_songs_prev[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_songs.shape)\n",
    "# print(data_songs_prev.shape)\n",
    "# data_songs=np.transpose(data_songs, (1,0,2,3))#Real data, input for model\n",
    "# data_songs_prev=np.transpose(data_songs_prev, (1,0,2,3))#Real data, 1 previous bar, input for model\n",
    "# print(data_songs.shape)\n",
    "# print(data_songs_prev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data_songs.npy', data_songs, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data_songs_prev.npy', data_songs_prev, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from model import MidiNet #Llamando el modelo\n",
    "from utils import pp, to_json, generation_test\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 20, \"Epoch to train [20]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.00005, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 12, \"The size of batch [12]\")\n",
    "flags.DEFINE_integer(\"output_w\", 16, \"The size of the output segs to produce [16]\")\n",
    "flags.DEFINE_integer(\"output_h\", 128, \"The size of the output note to produce [128]\")\n",
    "flags.DEFINE_integer(\"c_dim\", 1, \"Number of Midi track. [1]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Dircacectory name to save the image samples [samples]\")\n",
    "flags.DEFINE_string(\"dataset\", \"MidiNet_vg\", \"The name of dataset \")\n",
    "flags.DEFINE_boolean(\"is_train\", True, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"is_crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"generation_test\", False, \"True for generation_test, False for nothing [False]\")\n",
    "flags.DEFINE_string(\"gen_dir\", \"gen\", \"Directory name to save the generate samples [samples]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def main(_):\n",
    "    pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "    if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "        os.makedirs(FLAGS.checkpoint_dir)\n",
    "    if not os.path.exists(FLAGS.sample_dir):\n",
    "        os.makedirs(FLAGS.sample_dir)\n",
    "    if not os.path.exists(FLAGS.gen_dir):\n",
    "        os.makedirs(FLAGS.gen_dir)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if FLAGS.dataset == 'MidiNet_vg':\n",
    "            model = MidiNet(sess, batch_size=FLAGS.batch_size, output_w=FLAGS.output_w, output_h=FLAGS.output_h, c_dim=FLAGS.c_dim,\n",
    "                    dataset_name=FLAGS.dataset, is_crop=FLAGS.is_crop, checkpoint_dir=FLAGS.checkpoint_dir, sample_dir=FLAGS.sample_dir, \n",
    "                            gen_dir=FLAGS.gen_dir)\n",
    "        \n",
    "        if FLAGS.is_train:\n",
    "            model.train(FLAGS)\n",
    "        else:\n",
    "            model.load(FLAGS.checkpoint_dir)\n",
    "\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
